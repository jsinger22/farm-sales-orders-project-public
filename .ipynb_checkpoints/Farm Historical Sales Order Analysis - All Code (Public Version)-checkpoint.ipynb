{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494ace68",
   "metadata": {},
   "source": [
    "Major Sections in this Notebook:\n",
    " * [Data Collection](#Data-Collection)\n",
    " * [Data Cleaning & Prep](#Data-Cleaning-&-Prep)\n",
    " * [Analysis](#Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c78c76",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae880737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a67c3e",
   "metadata": {},
   "source": [
    "Get all the urls for the single item pages on apseyfarms.com that we'll need to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3498b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url_list):\n",
    "    links = []\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "        content = content.decode(\"utf-8\")\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        # find all the anchor tags with \"href\" attribute starting with \"https://\"\n",
    "        # and store the links in a list\n",
    "        for link in parser.find_all('a', attrs={'href': re.compile(\"/collections\")}):\n",
    "            links.append('http://www.apseyfarms.com' + link.get('href'))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e48312",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_scrape = ['https://apseyfarms.com/collections/beef-1', 'https://apseyfarms.com/collections/beef-1?page=2',\n",
    "                 'https://apseyfarms.com/collections/chicken', 'https://apseyfarms.com/collections/pork',\n",
    "                 'https://apseyfarms.com/collections/pork?page=2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_links = get_urls(urls_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5a7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_remove = ['http://www.apseyfarms.com/collections', 'http://www.apseyfarms.comhttps://apseyfarms.com/collections/bundles',\n",
    "                 'http://www.apseyfarms.com/collections/beef-1?page=2','http://www.apseyfarms.com/collections/beef-1?page=1',\n",
    "                 'http://www.apseyfarms.com/collections/pork?page=2','http://www.apseyfarms.com/collections/pork?page=1']\n",
    "for i in range(10):\n",
    "    for url in urls_to_remove:\n",
    "        try:\n",
    "            single_item_links.remove(url)\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ff69f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccb6f8",
   "metadata": {},
   "source": [
    "Now that we have all the urls from which we'll be scraping saved in a list, let's iterate through those sites and pull out the info we need: item name and quantity (package size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info(url_list):\n",
    "    item_dict = {}\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "        content = content.decode(\"utf-8\")\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        item_name_start_index = content.find('\"title\":\"') + len('\"title\":\"')\n",
    "        item_name_end_index = content.find('\",\"handle\":')\n",
    "        item_name = content[item_name_start_index:item_name_end_index]\n",
    "        \n",
    "        item_size_start_index = content.find('Package size:') + len('Package size:')\n",
    "        item_size_end_index = item_size_start_index + 50\n",
    "        item_size = content[item_size_start_index:item_size_end_index]\n",
    "        \n",
    "        item_dict[item_name] = item_size\n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dictionary with keys as item names and values as package size\n",
    "single_item_dict = get_item_info(single_item_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c7a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f960d08",
   "metadata": {},
   "source": [
    "The scraped info is a bit messy, so we'll save the dictionary to a pandas dataframe in order to clean up the data and structure into our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df = pd.DataFrame.from_dict(single_item_dict, orient='index').reset_index().rename(columns={'index':'item_name',0:'item_size'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b527d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the most part, it looks like the item quantity appears before the substring 'Ingredients'\n",
    "# so let's pull out everything before that substring into a new column\n",
    "single_item_df['item_size_new'] = single_item_df['item_size'].str.split('Ingredients').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ddc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up our new columns containing the item quantity\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\\n','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.l','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('roughly ','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.l','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.liq', 'b')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' \"> <!-- /snippets/social-meta-t','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' tubes','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' cuts','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' steaks','')\n",
    "\n",
    "# manually check and replace item sizes that didn't pull properly\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Tongue',['item_size_new']] = '1.5-2.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Rump Roast',['item_size_new']] = '2-3 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Flat Iron Steak',['item_size_new']] = '6-10 oz'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Round Roast',['item_size_new']] = '2-3 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Chicken - Whole',['item_size_new']] = '3.5-4.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Smoked Ham Roast',['item_size_new']] = '2.5-3.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Kielbasa',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Bratwurst',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Hocks',['item_size_new']] = '1.8-2.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Tongue',['item_size_new']] = '8 oz'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Bone-in Chops',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Boneless Chops',['item_size_new']] = '1 lb'\n",
    "\n",
    "# we'll give both 'Chicken - Eggs' items a quantity of 1\n",
    "single_item_df.iloc[40,2] = 1\n",
    "single_item_df.iloc[42,2] = 1\n",
    "\n",
    "# rename column with funky characters\n",
    "single_item_df.loc[single_item_df['item_name']=='Chicken - Legs \\\\u0026 Thighs',['item_name']] = 'Chicken - Legs & Thighs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the old item_size column and rename the new one\n",
    "single_item_df.drop('item_size',axis=1,inplace=True)\n",
    "single_item_df.rename(columns={'item_size_new':'item_size'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb92b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two items labeled 'Chicken - Eggs', which do not have an associated weight\n",
    "# let's go ahead and drop these rows\n",
    "single_item_df.drop([40,42],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the unit of measurement (lb, lbs, oz) into a new column\n",
    "def get_measure(value):\n",
    "    if 'lb' in value:\n",
    "        return 'lb'\n",
    "    elif 'oz' in value:\n",
    "        return 'oz'\n",
    "\n",
    "single_item_df['measure'] = single_item_df['item_size'].apply(get_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77266499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unit of measurement from the item_size column\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace(' lbs','').str.replace(' lb','').str.replace(' oz','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('lb','').str.replace('oz','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.strip()\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.rstrip()\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('\\ufeff','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('\\xa0s','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn ranges of values in the item_size column into a single value by taking the average of the range min and max\n",
    "# then create a new column with this value\n",
    "def find_avg_quantity(value):\n",
    "    quants = value.split('-')\n",
    "    if len(quants) == 1:\n",
    "        return value\n",
    "    elif len(quants) == 2:\n",
    "        return (float(quants[0])+float(quants[1]))/2\n",
    "    \n",
    "single_item_df['quantity'] = single_item_df['item_size'].apply(find_avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1258da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert quantities in oz to lbs\n",
    "single_item_df['quantity'] = single_item_df['quantity'].astype('float')\n",
    "single_item_df['quantity_lb'] = np.where(single_item_df['measure']=='oz', \n",
    "                                         single_item_df['quantity']/16, single_item_df['quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop old columns\n",
    "single_items = single_item_df.drop(['item_size','measure','quantity'],axis=1)\n",
    "single_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26943260",
   "metadata": {},
   "source": [
    "Now that we have the item info from apseyfarms.com cleaned up, let's restructure the dataframe into the format we'll need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk = single_items.copy()\n",
    "single_items_crosswalk['quantity_beef_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Beef'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)\n",
    "single_items_crosswalk['quantity_pork_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Pork'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)\n",
    "single_items_crosswalk['quantity_chicken_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Chicken'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1935076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_items_crosswalk['enterprise'] = 'tbd'\n",
    "single_items_crosswalk.iloc[0:30]['enterprise'] = 'Beef'\n",
    "single_items_crosswalk.iloc[30:42]['enterprise'] = 'Chicken'\n",
    "single_items_crosswalk.iloc[42:66]['enterprise'] = 'Pork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5da36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk.reset_index(inplace=True)\n",
    "single_items_crosswalk.drop('index',axis=1,inplace=True)\n",
    "single_items_crosswalk.rename(columns={'quantity_lb': 'total_quantity_lb'},inplace=True)\n",
    "single_items_crosswalk['quantity_turkey_lb'] = 0\n",
    "single_items_crosswalk['product_type'] = 'Single item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 75\n",
    "single_items_crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv that we can use later\n",
    "single_items_crosswalk.to_csv('single_items_crosswalk.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e38f47",
   "metadata": {},
   "source": [
    "# Data Cleaning & Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d98656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e6d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in orders data, single_items_crosswalk from Data Collection notebook, \n",
    "# and bundles_crosswalk (manually created csv from associated bundled product info)\n",
    "orders = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/orders_export_1.csv')\n",
    "single_items_crosswalk = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/single_items_crosswalk.csv')\n",
    "bundles_crosswalk = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/bundle_crosswalk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd144343",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2455ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb556b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundles_crosswalk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fab9f",
   "metadata": {},
   "source": [
    "## Create a single product crosswalk dataframe\n",
    "Ultimately, we want one product crosswalk that we'll use to cross-reference order data. So, let's get bundles_crosswalk into the same format as single_items_crosswalk and combine the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21840b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restructure bundles_crosswalk dataframe\n",
    "bundles_crosswalk.drop('Contents', axis=1, inplace=True)\n",
    "bundles_crosswalk['product_type'] = 'Bundle'\n",
    "bundles_crosswalk.rename(columns={'Bundle Name':'item_name', 'Beef':'quantity_beef_lb', \n",
    "                                 'Pork':'quantity_pork_lb', 'Chicken':'quantity_chicken_lb', \n",
    "                                 'Turkey':'quantity_turkey_lb', 'Total Weight':'total_quantity_lb',\n",
    "                                'Enterprise':'enterprise'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundles_crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ed68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine crosswalk dataframes\n",
    "product_crosswalk = pd.concat([single_items_crosswalk,bundles_crosswalk])\n",
    "product_crosswalk.reset_index(drop=True, inplace=True)\n",
    "product_crosswalk['Lineitem name'] = product_crosswalk['item_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f368b3",
   "metadata": {},
   "source": [
    "## Preliminary cleaning of orders data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fab371",
   "metadata": {},
   "source": [
    "Let's start by dropping columns we don't need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3537dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcefbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caca5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find columns with >50% of values missing\n",
    "cols_over_half_missing_values = list(orders.columns[orders.isnull().sum()/len(orders) > 0.5])\n",
    "cols_over_half_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now let's keep some of these columns we might use in our analysis and drop the rest \n",
    "# we'll also drop additional columns that won't be useful (e.g. 'Currency' only has one value of USD)\n",
    "drop_cols = cols_over_half_missing_values\n",
    "remove_from_drop_cols = ['Discount Code','Shipping Method','Shipping City','Shipping Zip',\n",
    "                                                'Shipping Province','Notes','Tags','Shipping Province Name']\n",
    "add_to_drop_cols = ['Currency','Billing Street','Billing Address1','Billing Country','Payment Reference','Vendor',\n",
    "                    'Outstanding Balance','Source']\n",
    "\n",
    "for col in remove_from_drop_cols:\n",
    "    drop_cols.remove(col)\n",
    "    \n",
    "for col in add_to_drop_cols:\n",
    "    drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72de701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d72f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns from orders dataset\n",
    "orders.drop(drop_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad212522",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d1b22",
   "metadata": {},
   "source": [
    "Let's convert the 'Created at' column to datetime, then create a new column with just the month and year of each order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f32f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['Created at'] = pd.to_datetime(orders['Created at'], utc=True).dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4116553",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['Created at'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['order_month'] = orders['Created at'].dt.strftime('%Y-%m')\n",
    "orders['order_month'] = pd.to_datetime(orders['order_month'])\n",
    "orders['order_month'] = orders['order_month'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08618399",
   "metadata": {},
   "source": [
    "Now let's explore some of our features to determine if there is additional cleaning we can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique line items (products)\n",
    "len(orders['Lineitem name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['Lineitem name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6642f",
   "metadata": {},
   "source": [
    "Looks like we have some suspicious \"products\" e.g. UPS Shipping. Since \"legit\" products most likely contain certain words e.g. \"beef\", \"pork\", \"chicken\", let's filter those out of the 'Lineitem name' columns and investigate suspicious further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33736161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary version\n",
    "suspicious_items_dict = {}\n",
    "for item in orders['Lineitem name']:\n",
    "    if not any(value in item.lower() for value in ('beef','pork','chicken','turkey','steak','bundle','box','bone','egg','steer','rib')):\n",
    "        if item in suspicious_items_dict:\n",
    "            suspicious_items_dict[item] += 1\n",
    "        elif item not in suspicious_items_dict:\n",
    "            suspicious_items_dict[item] = 1\n",
    "\n",
    "# list version\n",
    "suspicious_items_list = []\n",
    "for item in orders['Lineitem name']:\n",
    "    if not any(value in item.lower() for value in ('beef','pork','chicken','turkey','steak','bundle','box','bone','egg','steer','rib')):\n",
    "        suspicious_items_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b9ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "suspicious_items_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert dict to df\n",
    "suspicious_items_df = pd.DataFrame.from_dict(suspicious_items_dict, orient='index').reset_index()\n",
    "suspicious_items_df = suspicious_items_df.rename(columns={'index':'Lineitem name', 0:'count'})\n",
    "suspicious_items_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f50fe30",
   "metadata": {},
   "source": [
    "Now that we've narrowed our list of suspicious products down, let's investigate them further to determine if they should be removed from our dataset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949f348",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_suspicious_lines = len(orders[orders['Lineitem name'].isin(suspicious_items_list)])\n",
    "num_total_lines = len(orders)\n",
    "print('Count of suspicious line items:', num_suspicious_lines)\n",
    "print('Suspicious line items as a % of total line items:', round(num_suspicious_lines/num_total_lines*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c267797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders[orders['Lineitem name'].isin(suspicious_items_list)][['Lineitem name','Lineitem quantity','Total','Subtotal','Discount Amount',\n",
    "                                                       'Lineitem price','Created at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3079a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total amount paid from products\n",
    "orders[orders['Lineitem name'].isin(suspicious_items_list)]['Total'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6e52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lineitem names for suspicious_items with total = $0\n",
    "orders[(orders['Lineitem name'].isin(suspicious_items_list)) & (orders['Total']==0)]['Lineitem name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a4eb9",
   "metadata": {},
   "source": [
    "Since the majority of the suspicious_items have a total amount paid of $0 and suspicious_items only make up <3\\% of the total number of line items, let's drop these rows from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7410720",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_items_index = list(orders[orders['Lineitem name'].isin(suspicious_items_list)].index)\n",
    "orders = orders.drop(suspicious_items_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9cbda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that rows were dropped\n",
    "orders[orders['Lineitem name'].isin(suspicious_items_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ba68a",
   "metadata": {},
   "source": [
    "We know that Apsey Farms sometimes gives away products for free for promotions, gifts, etc. We won't consider these giveaways to be \"true\" sales/orders, so let's drop them from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orders[orders['Total']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6d80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for orders with $0 total\n",
    "orders[orders['Total']==0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff382628",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_giveaways_index = list(orders[orders['Total']==0].index)\n",
    "orders = orders.drop(free_giveaways_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c96f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that rows were dropped\n",
    "orders[orders['Total']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe9698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of line items (our true orders/sales) we're left with for analysis\n",
    "len(orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c72f07",
   "metadata": {},
   "source": [
    "## Modify product crosswalk to be a comprehensive single source of truth\n",
    "#### Add items from orders data not already in crosswalk to crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique item names from orders, convert to df, and add to crosswalk\n",
    "unique_lineitem_names = pd.DataFrame(orders['Lineitem name'].unique(), columns=['Lineitem name'])\n",
    "product_crosswalk_full = pd.concat([product_crosswalk,unique_lineitem_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e83cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_crosswalk_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "product_crosswalk_full.duplicated(['Lineitem name']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates, keeping the first entry as it contains the associated feature values\n",
    "product_crosswalk_full = product_crosswalk_full.drop_duplicates(['Lineitem name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm duplicates were dropped (370 - 72 = 298)\n",
    "product_crosswalk_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b40b87",
   "metadata": {},
   "source": [
    "#### Use Fuzzy Matching to impute values for missing items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f9247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's separate the items with known values from those with missing values\n",
    "known_items = product_crosswalk_full[product_crosswalk_full['item_name'].notna()]['item_name']\n",
    "missing_items = product_crosswalk_full[product_crosswalk_full['item_name'].isna()]['Lineitem name']\n",
    "print(known_items[:5])\n",
    "print('\\n')\n",
    "print(missing_items[:5])\n",
    "print('\\n')\n",
    "print('Total # known items:',len(known_items))\n",
    "print('Total # missing items:',len(missing_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9912b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fuzzywuzzy.process.extractOne() to find the top known item match for each missing item\n",
    "fuzzy_top_choice = {}\n",
    "for item in missing_items:\n",
    "    fuzzy_top_choice[item] = process.extractOne(item, known_items)\n",
    "fuzzy_top_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc1741",
   "metadata": {},
   "source": [
    "For the most part, it appears that choices with a score of 90 or greater (the second value in the choice tuple) are a good match with the missing item. However, it looks like fuzzywuzzy didn't do as great when the score is less than 90. So, we'll impute the values for missing items using choices with a score greater than or equal to 90, and use a different fuzzy function (fuzz.token_set_ratio) for cases where the score was less than 90 to pull out the top 3 matches so that we can manually choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb184594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use score_cutoff parameter to filter for good matches using process.extractOne\n",
    "fuzzy_top_choice = {}\n",
    "for item in missing_items:\n",
    "    fuzzy_top_choice[item] = process.extractOne(item, known_items, score_cutoff=89)\n",
    "fuzzy_top_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use these libraries to extract keys with top values from dictionaries\n",
    "import heapq\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through fuzzy_top_choice dictionary and create separate dataframes for good and bad matches\n",
    "\n",
    "fuzzy_below_90 = pd.DataFrame()\n",
    "good_matches = {}\n",
    "\n",
    "for key, value in fuzzy_top_choice.items():\n",
    "    # if score from fuzzy_top_choice was <90, find top three scores using fuzzy token_set_ratio \n",
    "    # and add to fuzzy_below_90 df\n",
    "    if value == None:\n",
    "        ratios = {}\n",
    "        for item in known_items:\n",
    "            ratios[item] = fuzz.token_set_ratio(key, item)\n",
    "        # get top 3 choices, returned as list of tuples where 1st element in tuple is the choice name and 2nd is fuzzy score\n",
    "        top_3_items = heapq.nlargest(3, ratios.items(), key=itemgetter(1))\n",
    "        # select only the choice name, not the score\n",
    "        top_3_choices = [i[0] for i in top_3_items]\n",
    "        top_3_choices_dict = {key: top_3_choices}\n",
    "        top_3_choices_df = pd.DataFrame.from_dict(top_3_choices_dict,orient='index',columns=['choice_1','choice_2',\n",
    "                                                                                             'choice_3'])\n",
    "        top_3_choices_df = top_3_choices_df.reset_index().rename(columns={'index':'Lineitem name'})\n",
    "        fuzzy_below_90 = pd.concat([fuzzy_below_90,top_3_choices_df])\n",
    "    \n",
    "    # if score from fuzzy_top_choice was >=90, add choice to good_matches_df\n",
    "    else:\n",
    "        good_matches[key] = value\n",
    "        good_matches_df = pd.DataFrame.from_dict(good_matches, orient='index', columns=['choice','score','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of \"good\" matches:',len(good_matches))\n",
    "print('Number of \"bad\" matches:',len(fuzzy_below_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe84ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_df = good_matches_df.reset_index().drop(['score','index'],axis=1)\n",
    "good_matches_df = good_matches_df.rename(columns={'level_0':'Lineitem name','choice':'item_name'})\n",
    "good_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_below_90 = fuzzy_below_90.reset_index().drop('index',axis=1)\n",
    "fuzzy_below_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace72e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export fuzzy_below_90 to csv so that we can manually label the best match\n",
    "fuzzy_below_90.to_csv('fuzzy_below_90.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31dc753",
   "metadata": {},
   "source": [
    "Let's impute values for good matches using the matching items in product_crosswalk_full, then we'll add the good matches back to our product crosswalk. Note that we'll need to drop the old, non-imputed items from product crosswalk; we'll do this at the end, after we've added values for good and bad matches to the product crosswalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches_impute = pd.merge(left=good_matches_df, right=product_crosswalk_full, how='left', on='item_name')\n",
    "good_matches_impute = good_matches_impute.drop('Lineitem name_y',axis=1).rename(columns={'Lineitem name_x':'Lineitem name'})\n",
    "good_matches_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final = pd.concat([product_crosswalk_full,good_matches_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad699f85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_crosswalk_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c0778a",
   "metadata": {},
   "source": [
    "We manually labeled the best choice for our fuzzy_below_90 matches. Let's pull the data back in and add it to our product crosswalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_below_90_labeled = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/fuzzy_below_90_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_below_90_labeled.drop(['Unnamed: 0','choice_1','choice_2','choice_3'],axis=1,inplace=True)\n",
    "fuzzy_below_90_labeled.rename(columns={'final_choice':'item_name'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d57423",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_below_90_labeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecf6de",
   "metadata": {},
   "source": [
    "Now we'll impute values for our fuzzy_below_90 matches using the matching items in product_crosswalk_full, then add those matches back to our product crosswalk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87fabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches_impute = pd.merge(left=fuzzy_below_90_labeled, right=product_crosswalk_full, how='left', on='item_name')\n",
    "fuzzy_matches_impute = fuzzy_matches_impute.drop('Lineitem name_y',axis=1).rename(columns={'Lineitem name_x':'Lineitem name'})\n",
    "fuzzy_matches_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec243ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches_impute['product_type'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b2a1c",
   "metadata": {},
   "source": [
    "Looks like we have a number of items that did not match a previously defined product, so we'll have to fill in values for these. Notes:\n",
    " * for \"bulk\" items, the 'Lineitem quantity' field in the orders data indicates the weight in pounds, rather than quantity of items ordered. We'll leave the quantity columns blank for now, and impute those values when we merge the product crosswalk back to our orders data.\n",
    " * items labeled \"eggs\" will not have an associated weight, rather we measure quantity by the dozen. So, we'll also leave the quantity columns blank for those items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches_impute.to_csv('fuzzy_matches_impute.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches_impute_labeled = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/fuzzy_matches_impute_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23fe8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches_impute_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c264f",
   "metadata": {},
   "source": [
    "Let's merge these items into our product crosswalk, then drop the old, non-imputed/duplicate items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744bd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final = pd.concat([product_crosswalk_final,fuzzy_matches_impute_labeled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b749bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_crosswalk_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25c6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final['item_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57948ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_items = list(product_crosswalk_final[product_crosswalk_final['item_name'].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083df074",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final = product_crosswalk_final.drop(null_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a87f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that null_items were dropped\n",
    "product_crosswalk_final['item_name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that product crosswalk contains 298 items\n",
    "len(product_crosswalk_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21eab7",
   "metadata": {},
   "source": [
    "#### Use weights specified in item names to update item attributes\n",
    "For example, 'Lineitem Name' = 'Ground Beef - 6 lbs' would previously have been matched with the standard ground beef item and assumed its standard quantity of 1 lb; however, 'quantity_beef_lb' for this item should instead be 6 (lbs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff7826f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find all Lineitem name's containing 'lb' or 'oz'\n",
    "# only include product_type = 'Single item' since we've manually populated values for some bundles and don't want\n",
    "# values for bulk items\n",
    "single_products = product_crosswalk_final[product_crosswalk_final['product_type']=='Single item']\n",
    "products_with_quantity = single_products[(single_products['Lineitem name'].str.contains('lb')) | (single_products['Lineitem name'].str.contains('oz'))]\n",
    "products_with_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03049dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract quantity\n",
    "# pattern = r\"[.+]\\s[.+]\\s(?P<quantity>[.+])\"\n",
    "# pattern_2 = r\"(\\d*\\.?\\d+[+]?[\\s]?[-]?[\\s]?[\\d*\\.?\\d+]?[\\.\\d+]?)\"\n",
    "pattern = r\"(?P<quantity>\\d*\\.?\\d+[+]?[\\s]?[-]?[\\s]?[\\d*]?[\\.]?[\\d*]?)\\s?(?P<measure>lbs?|lb?|oz?)\"\n",
    "quantity_extract = products_with_quantity['Lineitem name'].str.extract(pattern, flags=re.I)\n",
    "quantity_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbbe98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add extract to products_with_quantity dataframe by joining on the index\n",
    "products_quant_extracted = pd.merge(left=products_with_quantity, right=quantity_extract, how='left', left_index=True, right_index=True)\n",
    "products_quant_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480de9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with missing quantity values\n",
    "drop_rows = list(products_quant_extracted[products_quant_extracted['quantity'].isna()].index)\n",
    "products_quant_extracted = products_quant_extracted.drop(drop_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that rows were dropped\n",
    "print(products_quant_extracted['quantity'].isna().sum())\n",
    "print(len(products_quant_extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad5c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn ranges of values in the quantity column into a single value by taking the average of the range min and max\n",
    "# then create a new column with this value\n",
    "def find_avg_quantity(value):\n",
    "    quants = str(value).split('-')\n",
    "    if len(quants) == 1:\n",
    "        return value\n",
    "    elif len(quants) == 2:\n",
    "        return (float(quants[0])+float(quants[1]))/2\n",
    "    \n",
    "products_quant_extracted['quantity_avg'] = products_quant_extracted['quantity'].apply(find_avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc647aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_quant_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9e629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_quant_extracted['quantity_avg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc3e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '+' from quantity_avg\n",
    "# products_quant_extracted['quantity_avg'] = products_quant_extracted['quantity_avg'].str.replace('+','')\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    if '+' in str(value):\n",
    "        return value.replace('+','')\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "products_quant_extracted['quantity_avg'] = products_quant_extracted['quantity_avg'].apply(remove_plus_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188914b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_quant_extracted.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_quant_extracted['measure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4818eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert quantity_avg's in oz to lbs\n",
    "products_quant_extracted['quantity_avg'] = products_quant_extracted['quantity_avg'].astype('float')\n",
    "products_quant_extracted['quantity_avg_lb'] = np.where(products_quant_extracted['measure']=='oz', \n",
    "                                         products_quant_extracted['quantity_avg']/16, products_quant_extracted['quantity_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe4d6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products_quant_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea86b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use quantity_avg to update quantity values\n",
    "# excluding Turkey since we updated those manually previously\n",
    "products_quant_extracted['quantity_beef_lb'] = np.where(products_quant_extracted['enterprise']=='Beef',\n",
    "                                                     products_quant_extracted['quantity_avg_lb'],0)\n",
    "products_quant_extracted['quantity_pork_lb'] = np.where(products_quant_extracted['enterprise']=='Pork',\n",
    "                                                     products_quant_extracted['quantity_avg_lb'],0)\n",
    "products_quant_extracted['quantity_chicken_lb'] = np.where(products_quant_extracted['enterprise']=='Chicken',\n",
    "                                                     products_quant_extracted['quantity_avg_lb'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_quant_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b02d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset total_quantity_lb\n",
    "products_quant_extracted['total_quantity_lb'] = products_quant_extracted['quantity_beef_lb']+products_quant_extracted['quantity_pork_lb']+products_quant_extracted['quantity_chicken_lb']+products_quant_extracted['quantity_turkey_lb']\n",
    "products_quant_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unecessary columns\n",
    "products_quant_extracted = products_quant_extracted.drop(['quantity','measure','quantity_avg','quantity_avg_lb'],\n",
    "                                                        axis=1)\n",
    "products_quant_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_quant_extracted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9af50",
   "metadata": {},
   "source": [
    "Now that we've updated the quantity attributes for items that contained a quantity in their name, let's merge these items back into our product crosswalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf09f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final = pd.concat([product_crosswalk_final,products_quant_extracted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.duplicated(['Lineitem name']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310be0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we want to keep the last duplicate row, since products_quant_extracted was added to the end of the \n",
    "# product_crosswalk_final df\n",
    "product_crosswalk_final.drop_duplicates(['Lineitem name'],keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373117b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea83c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a4301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9daa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final['product_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final['enterprise'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4c278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_crosswalk_final.to_csv('product_crosswalk_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f544ce",
   "metadata": {},
   "source": [
    "## Add features to Orders data that we'll use in our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean = orders.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a699022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge orders with product crosswalk\n",
    "orders_clean = pd.merge(left=orders_clean, right=product_crosswalk_final, how='left', on='Lineitem name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d9e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b1567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_clean[orders_clean['total_quantity_lb'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new columns with the total item weight and weight per enterprise\n",
    "# note: doesn't apply to bulk items and eggs\n",
    "orders_clean['total_item_weight'] = orders_clean['Lineitem quantity'] * orders_clean['total_quantity_lb']\n",
    "orders_clean['item_weight_beef'] = orders_clean['Lineitem quantity'] * orders_clean['quantity_beef_lb']\n",
    "orders_clean['item_weight_pork'] = orders_clean['Lineitem quantity'] * orders_clean['quantity_pork_lb']\n",
    "orders_clean['item_weight_chicken'] = orders_clean['Lineitem quantity'] * orders_clean['quantity_chicken_lb']\n",
    "orders_clean['item_weight_turkey'] = orders_clean['Lineitem quantity'] * orders_clean['quantity_turkey_lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ccdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.to_csv('orders_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d218cd",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean = pd.read_csv('/Users/josh/Documents/Data Science/Apsey Farms/orders_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99837dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109766db",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 'Created at' to datetime\n",
    "orders_clean['Created at'] = pd.to_datetime(orders_clean['Created at'], utc=True).dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cbcb98",
   "metadata": {},
   "source": [
    "## Understanding the Customer Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ba17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of unique customers\n",
    "len(orders_clean['Email'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885d189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recurring customers\n",
    "(orders_clean.groupby('Email').size()>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_order_totals = pd.DataFrame(orders_clean.groupby('Email').sum()['Subtotal'].sort_values(ascending=False)).reset_index()\n",
    "customer_order_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691497f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(customer_order_totals['Subtotal'].sum())\n",
    "print(orders_clean['Subtotal'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e036c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_customer_dollars = customer_order_totals['Subtotal'].sum()\n",
    "total_customer_dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_order_totals['pct_of_total'] = customer_order_totals['Subtotal'] / total_customer_dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_order_totals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361c0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_order_totals['pct_of_total'].head(150).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running total/cumulative sum\n",
    "ax = customer_order_totals['pct_of_total'].cumsum().plot()\n",
    "ax.set(title='Cumulative Sum of Order Amount ($)', xlabel='Number of Customers', ylabel='% of Total Order Amount ($)')\n",
    "ax.axvline(x=150, color='r', linestyle='--')\n",
    "ax.axhline(y=0.75, color='r', linestyle='--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef37d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of orders\n",
    "orders_clean.groupby('Name').size().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recurring orders\n",
    "orders_clean['Tags'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b31e6",
   "metadata": {},
   "source": [
    "## Customer Order Amount by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a72cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_dollars = orders_clean.groupby('Shipping Province Name').sum()[['Subtotal']]\n",
    "state_dollars.reset_index(inplace=True)\n",
    "state_dollars.rename(columns={'Shipping Province Name':'state_name','Subtotal':'order_amount'},inplace=True)\n",
    "state_dollars.sort_values('order_amount',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc0f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orders_clean['Subtotal'].sum())\n",
    "print(state_dollars['order_amount'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee791e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean['Shipping Province Name'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23202be",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = gpd.read_file('/Users/josh/Documents/Data Science/Apsey Farms/States 21basic/geo_export_99f25753-6a02-4b7a-b22f-2d3e41e2a010.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd598",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a245b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aa4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Hawaii and Alaska\n",
    "state_map = usa.drop([0,50])\n",
    "state_map.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_map_dollars = pd.merge(left=state_map, right=state_dollars, how='left', on='state_name')\n",
    "state_map_dollars['order_amount'] = state_map_dollars['order_amount'].fillna(0)\n",
    "state_map_dollars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326ad09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dollar_states = list(state_dollars[state_dollars['order_amount']>=5000]['state_name'])\n",
    "medium_dollar_state = list(state_dollars[(state_dollars['order_amount']>=1000) & (state_dollars['order_amount']<5000)]['state_name'])\n",
    "low_dollar_states = list(state_dollars[state_dollars['order_amount']<1000]['state_name'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "state_map_dollars.plot(ax=ax, edgecolor='b', alpha=0.1)\n",
    "\n",
    "for n in state_dollars['state_name']:\n",
    "    if n in high_dollar_states:\n",
    "        state_map_dollars[state_map_dollars['state_name'] == f'{n}'].plot(ax=ax, color='darkred', edgecolor='b', linewidth=1)\n",
    "    elif n in medium_dollar_state:\n",
    "        state_map_dollars[state_map_dollars['state_name'] == f'{n}'].plot(ax=ax, color='lightcoral', edgecolor='b', linewidth=1)\n",
    "    elif n in low_dollar_states:\n",
    "        state_map_dollars[state_map_dollars['state_name'] == f'{n}'].plot(ax=ax, color='mistyrose', edgecolor='b', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f4b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# which states order the most of each enterprise\n",
    "orders_clean.groupby('Shipping Province Name').sum()[['item_weight_beef','item_weight_pork',\n",
    "                                                      'item_weight_chicken','item_weight_turkey']].sort_values('item_weight_beef',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f57a9",
   "metadata": {},
   "source": [
    "## Orders by Product Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf76fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.groupby('product_type').size().sort_values(ascending=False).plot.pie(autopct = '%.1f%%',\n",
    "                                                                                  colors=['cornflowerblue',\n",
    "                                                                                          'mediumseagreen',\n",
    "                                                                                          'coral'])\n",
    "plt.title('Product Type % of \\nTotal Number of Line Items Ordered')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e2b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.groupby('product_type').sum()['Subtotal'].sort_values(ascending=False).plot.pie(autopct = '%.1f%%',\n",
    "                                                                                             colors=['mediumseagreen',\n",
    "                                                                                                     'cornflowerblue',\n",
    "                                                                                                     'coral'])\n",
    "plt.title('Product Type % of Total Order Amount ($)')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly $ by product type\n",
    "annual_product_amt = pd.DataFrame(orders_clean.groupby([orders_clean['Created at'].dt.year,'product_type']).sum()['Subtotal'])\n",
    "annual_product_amt = annual_product_amt.reset_index()\n",
    "annual_product_amt = annual_product_amt.set_index(['Created at','product_type'])['Subtotal'].unstack().reset_index()\n",
    "annual_product_amt = annual_product_amt.set_index('Created at')\n",
    "annual_product_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b897c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = annual_product_amt.plot.bar(color=['coral','mediumseagreen','cornflowerblue'],stacked=True,rot=0)\n",
    "ax.set(xlabel='',ylabel='Order Amount ($)',title='Annual Order Amount ($) by Product Type');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7086c",
   "metadata": {},
   "source": [
    "## Orders by Enterprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5754fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.groupby('enterprise').size().sort_values(ascending=False).plot.pie(colors=['mediumseagreen',\n",
    "                                                                                       'cornflowerblue',\n",
    "                                                                                       'coral',\n",
    "                                                                                       'plum',\n",
    "                                                                                       'papayawhip',\n",
    "                                                                                       'lightgray',\n",
    "                                                                                       'lightsalmon',\n",
    "                                                                                       'gold'],\n",
    "                                                                                autopct = '%.1f%%',\n",
    "                                                                                figsize=(6,6))\n",
    "plt.title('Enterprise % of \\nTotal Number of Line Items Ordered')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_clean.groupby('enterprise').sum()['Subtotal'].sort_values(ascending=False).plot.pie(colors=['mediumseagreen',\n",
    "                                                                                       'papayawhip',\n",
    "                                                                                       'plum',\n",
    "                                                                                       'lightgray',\n",
    "                                                                                       'coral',\n",
    "                                                                                       'cornflowerblue',\n",
    "                                                                                       'gold',\n",
    "                                                                                       'lightsalmon'],\n",
    "                                                                                           autopct = '%.1f%%', \n",
    "                                                                                           figsize=(6,6))\n",
    "plt.title('Enterprise % of Total Order Amount ($)')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_enterprise_amt = pd.DataFrame(orders_clean.groupby([orders_clean['Created at'].dt.year,'enterprise']).sum()['Subtotal'])\n",
    "annual_enterprise_amt = annual_enterprise_amt.reset_index()\n",
    "annual_enterprise_amt = annual_enterprise_amt.set_index(['Created at','enterprise'])['Subtotal'].unstack().reset_index()\n",
    "annual_enterprise_amt = annual_enterprise_amt.set_index('Created at')\n",
    "annual_enterprise_amt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = annual_enterprise_amt.plot.bar(color=['mediumseagreen','plum','lightgray',\n",
    "                                           'papayawhip','coral','lightsalmon','cornflowerblue','gold'],\n",
    "                                    stacked=True,rot=0)\n",
    "ax.set(xlabel='',ylabel='Order Amount ($)',title='Annual Order Amount ($) by Enterprise')\n",
    "ax.legend(bbox_to_anchor=(1,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f31f56",
   "metadata": {},
   "source": [
    "## Orders by Enterprise-Product Type Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of line items\n",
    "ax = orders_clean.groupby(['enterprise','product_type']).size().sort_values().plot.barh()\n",
    "ax.set(xlabel='Number of Line Items', ylabel='', title='Total Number of Line Items by Enterprise & Product Type');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82345c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order amounts\n",
    "ax = orders_clean.groupby(['enterprise','product_type']).sum()['Subtotal'].sort_values().plot.barh()\n",
    "ax.set(xlabel='Order Amount ($)', ylabel='', title='Total Order Amount by Enterprise & Product Type');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528eeb2",
   "metadata": {},
   "source": [
    "Create two separate dataframes then merge into one: 1) total # line items & % of total by enterprise-product combination, 2) total order amount ($) and % of total by enterprise-product combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e01590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# order amount by enterprise-product combinations\n",
    "order_combs_dollar = orders_clean.groupby(['enterprise','product_type']).sum()['Subtotal'].sort_values(ascending=False)\n",
    "order_combs_dollar_df = pd.DataFrame(order_combs_dollar)\n",
    "order_combs_dollar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffebeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_combs_dollar_df['enterprise_product_type'] = order_combs_dollar_df.index\n",
    "order_combs_dollar_df.reset_index(inplace=True)\n",
    "order_combs_dollar_df.drop(['enterprise','product_type'],axis=1,inplace=True)\n",
    "order_combs_dollar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa3f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total $ for all orders\n",
    "total_orders_amt = orders_clean['Subtotal'].sum()\n",
    "\n",
    "# add % of total to order_combs_df\n",
    "order_combs_dollar_df['$_pct_of_total'] = (order_combs_dollar_df['Subtotal'] / total_orders_amt) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of line items by enterprise-product combinations\n",
    "order_combs_num = orders_clean.groupby(['enterprise','product_type']).size().sort_values(ascending=False)\n",
    "order_combs_num_df = pd.DataFrame(order_combs_num)\n",
    "order_combs_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ea582",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_combs_num_df['enterprise_product_type'] = order_combs_num_df.index\n",
    "order_combs_num_df.reset_index(inplace=True)\n",
    "order_combs_num_df.drop(['enterprise','product_type'],axis=1,inplace=True)\n",
    "order_combs_num_df.rename(columns={0:'num_line_items'},inplace=True)\n",
    "order_combs_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb6e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total $ for all orders\n",
    "total_orders_num = len(orders_clean)\n",
    "\n",
    "# add % of total to order_combs_df\n",
    "order_combs_num_df['#_pct_of_total'] = (order_combs_num_df['num_line_items'] / total_orders_num) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab95004",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_combs_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6448d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "order_combs_final = pd.merge(left= order_combs_num_df, right=order_combs_dollar_df, how='left', on='enterprise_product_type')\n",
    "order_combs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0c1ed",
   "metadata": {},
   "source": [
    "## Drill Down: Products Ordered - All Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 products, not taking into account total #/weight ordered\n",
    "ax = orders_clean['item_name'].value_counts().head(20).sort_values().plot.barh(figsize=(6,6), \n",
    "                                                                          title='Top 20 Products Ordered')\n",
    "ax.set(xlabel='Number of Line Items');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = orders_clean.groupby('item_name').sum()['Subtotal'].sort_values(ascending=False).head(20).sort_values().plot.barh(figsize=(6,6))\n",
    "ax.set(title='Top 20 Products Ordered by Amount ($): Jan 2018 - July 2021', xlabel='Amount ($)',ylabel='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56338348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5 revenue-generating products ordered by month\n",
    "top_5_products = list(orders_clean.groupby('item_name').sum()['Subtotal'].sort_values(ascending=False).head(5).index)\n",
    "top_5_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f91609",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = orders_clean[orders_clean['item_name'].isin(top_5_products)].groupby('order_month').sum()['Subtotal'].plot()\n",
    "ax.set(title='Monthly Revenue for Top 5 Revenue-Generating Products', xlabel='Month of Order', ylabel='Amount ($)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0011f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom in on 2020 and 2021\n",
    "ax = orders_clean[(orders_clean['item_name'].isin(top_5_products)) & ((orders_clean['Created at'].dt.year==2020) | (orders_clean['Created at'].dt.year==2021))].groupby('order_month').sum()['Subtotal'].plot.bar()\n",
    "ax.set(title='Monthly Revenue for Top 5 Revenue-Generating Products', xlabel='Month of Order', ylabel='Amount ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce05df6",
   "metadata": {},
   "source": [
    "Find the monthly average revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_stats = orders_clean.groupby(orders_clean['Created at'].dt.month).sum()\n",
    "monthly_stats['avg_revenue'] = monthly_stats['Subtotal']/4\n",
    "monthly_stats = monthly_stats[['Subtotal','avg_revenue']]\n",
    "monthly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only have data through 7/2021, so avg_revenue should be 'Subtotal'/ 3 years for months 8-12\n",
    "monthly_stats.iloc[7,1] = 14455.28/3\n",
    "monthly_stats.iloc[8,1] = 11828.31/3\n",
    "monthly_stats.iloc[9,1] = 17664.57/3\n",
    "monthly_stats.iloc[10,1] = 28194.84/3\n",
    "monthly_stats.iloc[11,1] = 25061.41/3\n",
    "monthly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56795c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly averages, where Jan = 1 and Dec = 12\n",
    "ax = monthly_stats['avg_revenue'].plot.bar(rot=0)\n",
    "ax.set(title='Average Monthly Revenue from All Product Orders', xlabel='Month', ylabel='Average Amount ($)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d966bd8",
   "metadata": {},
   "source": [
    "## Drill Down: Products Ordered - Single Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad2ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 single items by $\n",
    "single_item_orders = orders_clean[orders_clean['product_type']=='Single item']\n",
    "ax = single_item_orders.groupby('item_name').sum()['Subtotal'].sort_values(ascending=False).head(10).sort_values().plot.barh()\n",
    "ax.set(title='Top 10 Single Items Ordered by Amount ($): \\nJan 2018 - July 2021', xlabel='Amount ($)',ylabel='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56306ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_orders_recent = orders_clean[(orders_clean['product_type']=='Single item') & ((orders_clean['Created at'].dt.year==2020) | (orders_clean['Created at'].dt.year==2021))]\n",
    "ax = single_item_orders_recent.groupby('item_name').sum()['Subtotal'].sort_values(ascending=False).head(10).sort_values().plot.barh()\n",
    "ax.set(title='Top 10 Single Items Ordered by Amount ($): \\nJan 2020 - July 2021', xlabel='Amount ($)',ylabel='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ed333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate price per pound for single items\n",
    "single_item_orders['price_per_pound'] = single_item_orders['Lineitem price']/single_item_orders['total_item_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_orders.groupby('item_name').mean()['price_per_pound'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff2d290",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_orders[single_item_orders['item_name']=='Beef - Hanger Steak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top single items by weight - if uneven, might indicate not utilizing full carcass\n",
    "ax = single_item_orders.groupby('item_name').sum()['total_item_weight'].sort_values(ascending=False).head(10).sort_values().plot.barh()\n",
    "ax.set(title='Top 10 Single Items Ordered by Weight (lbs): \\nJan 2018 - July 2021', xlabel='Amount ($)',ylabel='');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2bdc32",
   "metadata": {},
   "source": [
    "## Drill Down: Products Ordered - Bundles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2064e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 bundles by $\n",
    "bundle_orders = orders_clean[orders_clean['product_type']=='Bundle']\n",
    "ax = bundle_orders.groupby('item_name').sum()['Subtotal'].sort_values(ascending=False).head(10).sort_values().plot.barh()\n",
    "ax.set(title='Top 10 Bundles Ordered by Amount ($): \\nJan 2018 - July 2021', xlabel='Amount ($)',ylabel='');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
