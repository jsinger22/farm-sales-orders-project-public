{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae880737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a67c3e",
   "metadata": {},
   "source": [
    "Get all the urls for the single item pages on apseyfarms.com that we'll need to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3498b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url_list):\n",
    "    links = []\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "        content = content.decode(\"utf-8\")\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        # find all the anchor tags with \"href\" attribute starting with \"https://\"\n",
    "        # and store the links in a list\n",
    "        for link in parser.find_all('a', attrs={'href': re.compile(\"/collections\")}):\n",
    "            links.append('http://www.apseyfarms.com' + link.get('href'))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e48312",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_scrape = ['https://apseyfarms.com/collections/beef-1', 'https://apseyfarms.com/collections/beef-1?page=2',\n",
    "                 'https://apseyfarms.com/collections/chicken', 'https://apseyfarms.com/collections/pork',\n",
    "                 'https://apseyfarms.com/collections/pork?page=2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_links = get_urls(urls_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5a7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_remove = ['http://www.apseyfarms.com/collections', 'http://www.apseyfarms.comhttps://apseyfarms.com/collections/bundles',\n",
    "                 'http://www.apseyfarms.com/collections/beef-1?page=2','http://www.apseyfarms.com/collections/beef-1?page=1',\n",
    "                 'http://www.apseyfarms.com/collections/pork?page=2','http://www.apseyfarms.com/collections/pork?page=1']\n",
    "for i in range(10):\n",
    "    for url in urls_to_remove:\n",
    "        try:\n",
    "            single_item_links.remove(url)\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ff69f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccb6f8",
   "metadata": {},
   "source": [
    "Now that we have all the urls from which we'll be scraping saved in a list, let's iterate through those sites and pull out the info we need: item name and quantity (package size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc21b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info(url_list):\n",
    "    item_dict = {}\n",
    "    for url in url_list:\n",
    "        response = requests.get(url)\n",
    "        content = response.content\n",
    "        content = content.decode(\"utf-8\")\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        \n",
    "        item_name_start_index = content.find('\"title\":\"') + len('\"title\":\"')\n",
    "        item_name_end_index = content.find('\",\"handle\":')\n",
    "        item_name = content[item_name_start_index:item_name_end_index]\n",
    "        \n",
    "        item_size_start_index = content.find('Package size:') + len('Package size:')\n",
    "        item_size_end_index = item_size_start_index + 50\n",
    "        item_size = content[item_size_start_index:item_size_end_index]\n",
    "        \n",
    "        item_dict[item_name] = item_size\n",
    "    return item_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b2687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a dictionary with keys as item names and values as package size\n",
    "single_item_dict = get_item_info(single_item_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c7a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_item_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f960d08",
   "metadata": {},
   "source": [
    "The scraped info is a bit messy, so we'll save the dictionary to a pandas dataframe in order to clean up the data and structure into our desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df = pd.DataFrame.from_dict(single_item_dict, orient='index').reset_index().rename(columns={'index':'item_name',0:'item_size'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b527d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d9ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the most part, it looks like the item quantity appears before the substring 'Ingredients'\n",
    "# so let's pull out everything before that substring into a new column\n",
    "single_item_df['item_size_new'] = single_item_df['item_size'].str.split('Ingredients').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ddc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up our new columns containing the item quantity\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\\n','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.l','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('roughly ','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.l','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace('\"> <!-- /snippets/social-meta-tags.liq', 'b')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' \"> <!-- /snippets/social-meta-t','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' tubes','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' cuts','')\n",
    "single_item_df['item_size_new'] = single_item_df['item_size_new'].str.replace(' steaks','')\n",
    "\n",
    "# manually check and replace item sizes that didn't pull properly\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Tongue',['item_size_new']] = '1.5-2.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Rump Roast',['item_size_new']] = '2-3 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Flat Iron Steak',['item_size_new']] = '6-10 oz'\n",
    "single_item_df.loc[single_item_df['item_name']=='Beef - Round Roast',['item_size_new']] = '2-3 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Chicken - Whole',['item_size_new']] = '3.5-4.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Smoked Ham Roast',['item_size_new']] = '2.5-3.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Kielbasa',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Bratwurst',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Hocks',['item_size_new']] = '1.8-2.5 lbs'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Tongue',['item_size_new']] = '8 oz'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Bone-in Chops',['item_size_new']] = '1 lb'\n",
    "single_item_df.loc[single_item_df['item_name']=='Pork - Boneless Chops',['item_size_new']] = '1 lb'\n",
    "\n",
    "# we'll give both 'Chicken - Eggs' items a quantity of 1\n",
    "single_item_df.iloc[40,2] = 1\n",
    "single_item_df.iloc[42,2] = 1\n",
    "\n",
    "# rename column with funky characters\n",
    "single_item_df.loc[single_item_df['item_name']=='Chicken - Legs \\\\u0026 Thighs',['item_name']] = 'Chicken - Legs & Thighs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the old item_size column and rename the new one\n",
    "single_item_df.drop('item_size',axis=1,inplace=True)\n",
    "single_item_df.rename(columns={'item_size_new':'item_size'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b8fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb92b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have two items labeled 'Chicken - Eggs', which do not have an associated weight\n",
    "# let's go ahead and drop these rows\n",
    "single_item_df.drop([40,42],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the unit of measurement (lb, lbs, oz) into a new column\n",
    "def get_measure(value):\n",
    "    if 'lb' in value:\n",
    "        return 'lb'\n",
    "    elif 'oz' in value:\n",
    "        return 'oz'\n",
    "\n",
    "single_item_df['measure'] = single_item_df['item_size'].apply(get_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edccb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77266499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the unit of measurement from the item_size column\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace(' lbs','').str.replace(' lb','').str.replace(' oz','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('lb','').str.replace('oz','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.strip()\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.rstrip()\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('\\ufeff','')\n",
    "single_item_df['item_size'] = single_item_df['item_size'].str.replace('\\xa0s','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn ranges of values in the item_size column into a single value by taking the average of the range min and max\n",
    "# then create a new column with this value\n",
    "def find_avg_quantity(value):\n",
    "    quants = value.split('-')\n",
    "    if len(quants) == 1:\n",
    "        return value\n",
    "    elif len(quants) == 2:\n",
    "        return (float(quants[0])+float(quants[1]))/2\n",
    "    \n",
    "single_item_df['quantity'] = single_item_df['item_size'].apply(find_avg_quantity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e4468",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1258da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert quantities in oz to lbs\n",
    "single_item_df['quantity'] = single_item_df['quantity'].astype('float')\n",
    "single_item_df['quantity_lb'] = np.where(single_item_df['measure']=='oz', \n",
    "                                         single_item_df['quantity']/16, single_item_df['quantity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop old columns\n",
    "single_items = single_item_df.drop(['item_size','measure','quantity'],axis=1)\n",
    "single_items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26943260",
   "metadata": {},
   "source": [
    "Now that we have the item info from apseyfarms.com cleaned up, let's restructure the dataframe into the format we'll need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc30cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk = single_items.copy()\n",
    "single_items_crosswalk['quantity_beef_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Beef'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)\n",
    "single_items_crosswalk['quantity_pork_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Pork'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)\n",
    "single_items_crosswalk['quantity_chicken_lb'] = np.where(single_items_crosswalk['item_name'].str.contains('Chicken'),\n",
    "                                                     single_items_crosswalk['quantity_lb'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1935076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_items_crosswalk['enterprise'] = 'tbd'\n",
    "single_items_crosswalk.iloc[0:30]['enterprise'] = 'Beef'\n",
    "single_items_crosswalk.iloc[30:42]['enterprise'] = 'Chicken'\n",
    "single_items_crosswalk.iloc[42:66]['enterprise'] = 'Pork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5da36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_items_crosswalk.reset_index(inplace=True)\n",
    "single_items_crosswalk.drop('index',axis=1,inplace=True)\n",
    "single_items_crosswalk.rename(columns={'quantity_lb': 'total_quantity_lb'},inplace=True)\n",
    "single_items_crosswalk['quantity_turkey_lb'] = 0\n",
    "single_items_crosswalk['product_type'] = 'Single item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fd748",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 75\n",
    "single_items_crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to a csv that we can use later\n",
    "single_items_crosswalk.to_csv('single_items_crosswalk.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
